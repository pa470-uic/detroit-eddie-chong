---
title: "Detroit Part 1"
author: "Eddie Chong"
date: "2/6/2022"
output: html_document
code_folding: hide
    df_print: paged
    theme: sandstone
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(tidyverse)
library(lubridate)
library(DBI)
library(RSQLite)
```

Template file. Code will be included in folded blocks in the output to facilitate grading. Please knit this file and commit both the rmd and the html output. If you add external files to your analysis, please commit them to the files folder in this repository. NOTE: please do not commit large (15MB+) files to GitHub. Instead please denote the origin of the files in your code. 

```{r}
con <- DBI::dbConnect(RSQLite::SQLite(), "detroit.sqlite")

assessments <- dbReadTable(con, "assessments")
blight <- dbReadTable(con, "blight")
foreclosures <- dbReadTable(con, "foreclosures")
parcels <- dbReadTable(con, "parcels")
parcel_hist <- dbReadTable(con, "parcels_historic")
sales <- dbReadTable(con, "sales")

```

# Section A: Conduct an exploratory data analysis of homes in Detroit. Offer an overview of relevant trends in the data and data quality issues. Contextualize your analysis with key literature on properties in Detroit.

```{r}

# Missing Values
sapply(assessments, function(x) sum(is.na(x)))
sapply(blight, function(x) sum(is.na(x)))
sapply(foreclosures, function(x) sum(is.na(x)))
sapply(sales, function(x) sum(is.na(x)))
sapply(parcels, function(x) sum(is.na(x)))
sapply(parcel_hist, function(x) sum(is.na(x)))

####################################################

summary(assessments$ASSESSEDVALUE)
summary(assessments$TAXABLEVALUE)

######################################################
assessments %>%
  filter(ASSESSEDVALUE<100000) %>%
  ggplot(aes(x=ASSESSEDVALUE)) +
  geom_histogram(bins=30)

assessments %>%
  filter(TAXABLEVALUE<10000)%>%
  ggplot(aes(x=TAXABLEVALUE)) +
  geom_histogram(bins=30)
```

When looking at the current state of housing in Detroit, it is the outcome of deindustrialization that displaced residents, governmental mismanagement, and structural inequality that put more burden on marginalized residents. However, the people who still reside in Detroit face challenges in terms of the inequities between how homes are assessed and taxed. 

In terms of general data quality, the assessments dataset is very robust with no missing values. Sales data is also relatively low in the amount of missing values that potentially can be addressed in data cleaning. The foreclosure dataset is of concern since it is organized in a manner that makes analysis difficult since it is essentially dichotomous variable over the years. 

When looking at the general distribution of assessed and taxable value of properties, the majority of property are skewed lower, if not at zero. 

References:
Presbey, G. M. (2015). Globalization and the Crisis in Detroit. Perspectives on Global Development and Technology, 14(1-2), 261-277.

Tabb, W. K. (2015). If Detroit is dead, some things need to be said at the funeral. Journal of Urban Affairs, 37(1), 1-12.

# Section B: Use cmfproperty to conduct a sales ratio study across the relevant time period. Note that cmfproperty is designed to produce Rmarkdown reports but use the documentation and insert relevant graphs/figures into your report. Look to make this reproducible since you’ll need these methods to analyze your assessment model later on. Detroit has many sales which are not arm’s length (sold at fair market value) so some sales should be excluded, but which ones?

```{r}
library(cmfproperty)
# Following the example on the package documentation, I combined sales data which contained sales price with assessment data that 
sales1 <- sales %>%
  rename(PARCELNO=parcel_num)

assess_sales <- left_join(assessments, sales1, by= "PARCELNO")
colnames(assess_sales)

assess_sales1 <- assess_sales %>%
  select(PARCELNO, sale_price, ASSESSEDVALUE, year)

ratios <-
  cmfproperty::reformat_data(
    assess_sales1,
    PARCELNO = "PIN",
    sale_price = "SALE_PRICE",
    ASSESSEDVALUE = "ASSESSED_VALUE",
    year = "SALE_YEAR",
  )
# I tried replicating how the Cook County example data was formatted, but I kept getting errors that said there are unused arguments and could not figure out what I was doing wrong.
```
  

# Section C: Explore trends and relationships with property sales using simple regressions

```{r}

sales2 <- sales %>%
  mutate(sale_term1 = recode(sale_terms, "not arms length" = "NOT ARMS LENGTH", "Not Arms Length" = "NOT ARMS LENGTH", "valid arms length" ="VALID ARMS LENGTH", "Valid Arms Length" = "VALID ARMS LENGTH", .default="Other")) %>%
  mutate(prop_class = as.character(property_c))
 # mutate(year = as.POSIXct(sale_date, format = "%m/%d/%Y %H:%M:%S")) %>%
  #mutate(year1= format(sale_date, format="%Y")) %>%
  #select(sale_term1, sale_price, property_c, year1)

# in order to collapse some of the variables, I focused on property class and sales terms. In terms of looking at if the ratio between valuation and sale price, I decided to focus on if the sale was within or not of "arms length".

#(I tried to add years, but for some reason I could not get the year to properly extract and the linear regression for some reason went into the 7.8GB range?)


lmsales <- lm(sale_price ~ prop_class + sale_term1, data = sales2)
summary(lmsales)
```

In this particular model, sales price is statistically significant when considering property class and if the sale was within arms length. If a property was within Valid Arms length, the predicted sales price would decrease by over $35,000. The most valuable property class is 483 with prices increasing by over $750,000. The lease valuable property class being 465 with sales price decreasing by nearly $16,000.

# Section D: Explore trends and relationships with foreclosures using simple regressions

```{r}
foreclosure1 <- foreclosures %>%
  rename(prop_parcelnum = PARCELNO)

assess_sale_fc <- left_join(assess_sales1, foreclosure1, by= "PARCELNO")

lmforclosure <- lm()

# I am having much difficulty with the assignment and my computer is currently struggling to deal with how large some of these computations are. I am struggling with the open-ended nature of this assignment. R kept crashing and I do not know id this is a hardware issue or if I am making this much more difficult than it needs to be.

```